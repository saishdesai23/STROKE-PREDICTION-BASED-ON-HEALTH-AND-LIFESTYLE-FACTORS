---
title: "Methods of Data Science : Final Year Project"
author: "Saish Desai"
date: "3/18/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# installation of all the packages
install.packages("ggstatsplot")

# loading all the packages
library("ggstatsplot")
library(dplyr)
library(mltools)
library(data.table)
library(ROSE)
library(rpart)
library(tree)
library(randomForest)
library(caret)
```

## R Markdown

Predicting survivability of Hepatitis Patient

# Importing the dataset
```{r}
stroke_data = read.csv("/Users/saishdesai/Documents/UIUC_MSIM/Spring 2022/Methods of DS IS 517/Final_Project/Data/healthcare-dataset-stroke-data.csv")
head(stroke_data)
```

## Including Plots

# Describing the data
```{r}
str(stroke_data)
```

# Factorizing all the categorical variables
```{r}
# reference for one hot coding - https://datatricks.co.uk/one-hot-encoding-in-r-three-simple-methods

stroke_data$gender_cat = factor(stroke_data$gender,levels = c('Male', 'Female'),labels = c(0,1))
stroke_data$ever_married_cat = factor(stroke_data$ever_married,levels = c('No', 'Yes'),labels = c(0,1))
stroke_data$Residence_type_cat = factor(stroke_data$Residence_type,levels = c('Rural', 'Urban'),labels = c(0,1))

stroke_data$hypertension = factor(stroke_data$hypertension,levels = c('0', '1'),labels = c(0,1))

stroke_data$heart_disease = factor(stroke_data$heart_disease,levels = c('0', '1'),labels = c(0,1))

stroke_data$smoking_status_cat = factor(stroke_data$smoking_status,levels = c("formerly smoked", "never smoked", "smokes","Unknown"),labels = c(0,1,2,3))
stroke_data$work_type_cat = factor(stroke_data$work_type,levels = c("children", "Govt_job", "Never_worked", "Private","Self-employed"),labels = c(0,1,2,3,4))

stroke_data['bmi'] <- as.numeric(stroke_data$bmi)
```

```{r}
stroke_data_clean = subset(stroke_data, select = -c(gender,ever_married,work_type,Residence_type,smoking_status,work_type) )
str(stroke_data_clean)
```

# Missing values in the dataset
```{r}
# printing columns with missing values
missing <- names(which(colSums(is.na(stroke_data_clean))>0))

print(missing)

for(ele in missing){
  null_count <- sum(is.na(stroke_data_clean[ele]))
  null_percent <- null_count*100/nrow(stroke_data_clean)
  print(ele)
  print(null_count)
  print(null_percent)
  
}
```

```{r}
mean_bmi <- mean(na.omit(stroke_data_clean$bmi))
median_bmi <- median(na.omit(stroke_data_clean$bmi))

# estimating the mode value of the bmi column
# reference - https://www.tutorialspoint.com/r/r_mean_median_mode.htm
getmode <- function(v) {
   uniqv <- unique(v)
   index <-which.max(tabulate(match(v, uniqv))) #index of the most occuring value
   uniqv[index]
}
mode_bmi <- getmode(na.omit(stroke_data_clean$bmi))


print(mean_bmi)
print(median_bmi)
print(mode_bmi)

# distribution for BMI
d <- density(na.omit(stroke_data_clean$bmi))
plot(d, main="Distribution for BMI ")
polygon(d, col="green", border="blue")

# distribution for age
d <- density(na.omit(stroke_data_clean$age))
plot(d, main="Distribution for Age ")
polygon(d, col="red", border="blue")

# distribution for avg_glucose_level
d <- density(na.omit(stroke_data_clean$avg_glucose_level))
plot(d, main="Distribution for Avg_glucose_level")
polygon(d, col="yellow", border="blue")

```

Imputation of missing values with mean of the values from the column 'bmi'
```{r}
stroke_data_clean$bmi[is.na(stroke_data_clean$bmi)] <- mean(stroke_data_clean$bmi, na.rm = TRUE)
stroke_data_clean <- na.omit(stroke_data_clean)
str(stroke_data_clean)
```
# Outlier removal
```{r}
#boxplot before outlier removal
boxplot(eliminated$age, main="Age distribution",
   xlab="ID", ylab="Age")

boxplot(eliminated$bmi, main="Bmi distribution",
   xlab="ID", ylab="bmi")

boxplot(eliminated$avg_glucose_level, main="Avg glucose level distribution",
   xlab="ID", ylab="avg_glucose_level")

```


```{r}
#IQR

Q_age <- quantile(stroke_data_clean$age, probs=c(.25, .75), na.rm = FALSE)
iqr_age <- IQR(stroke_data_clean$age)

Q_bmi<- quantile(stroke_data_clean$bmi, probs=c(.25, .75), na.rm = FALSE)
iqr_bmi <- IQR(stroke_data_clean$bmi)
 
Q_avg_glucose_level<- quantile(stroke_data_clean$avg_glucose_level, probs=c(.25, .75), na.rm = FALSE)
iqr_avg_glucose_level <- IQR(stroke_data_clean$avg_glucose_level)


eliminated<- subset(stroke_data_clean, 
                    stroke_data_clean$age > (Q_age[1] - 1.5*iqr_age) & 
                    stroke_data_clean$age < (Q_age[2]+1.5*iqr_age) & 
                    stroke_data_clean$bmi > (Q_bmi[1] - 1.5*iqr_bmi) & 
                    stroke_data_clean$bmi < (Q_bmi[2]+1.5*iqr_bmi) & 
                    stroke_data_clean$avg_glucose_level > (Q_avg_glucose_level[1] - 1.5*iqr_avg_glucose_level) &
                    stroke_data_clean$avg_glucose_level < (Q_avg_glucose_level[2]+1.5*iqr_avg_glucose_level))




```

```{r}
#boxplot after outlier removal
boxplot(eliminated$age, main="Age distribution",
   xlab="ID", ylab="Age")

boxplot(eliminated$bmi, main="Bmi distribution",
   xlab="ID", ylab="bmi")

boxplot(eliminated$avg_glucose_level, main="Avg glucose level distribution",
   xlab="ID", ylab="avg_glucose_level")

table(eliminated$stroke)

# min max standardization function
fun_range <- function(x) {                             
  (x - min(x)) / (max(x) - min(x))
}
# perform normalization
eliminated$age <- fun_range(x = eliminated$age)
eliminated$bmi <- fun_range(x = eliminated$bmi)
eliminated$avg_glucose_level <- fun_range(x = eliminated$avg_glucose_level)


```
```{r}
eliminated$stroke<-as.factor(eliminated$stroke)

# train test split
split1<- sample(c(rep(0, 0.7 * nrow(eliminated)), rep(1, 0.3 * nrow(eliminated))))

train <- eliminated[split1 == 0, ]
test <- eliminated[split1== 1, ]

rf <- randomForest(stroke ~., data = train, mtry =sqrt(ncol(train) - 1), ntree = 500)


# predicting the income value
yhat_rf <- predict(rf, test[,-7])

# accuracy
acc_rf = mean(yhat_rf == test$stroke)

# classification metrics
cm <- confusionMatrix(yhat_rf, test$stroke, mode = "everything", positive="1")
cm
```
Due to a high class imbalance all the entries are classified as belonging to class 0. This will lead to Pecision and Recall value of "0", thus making the F1-score undefined.

```{r}
# data <- ROSE(stroke~., stroke_data_clean, p=0.5, hmult.majo=1, hmult.mino=1)$data
data_balanced_over <- ovun.sample(stroke~ ., data = train, p=0.6, method = "over")$data
table(data_balanced_over$stroke)
```

The data is highly impbalanced due to the fact the there are very few people having suffered from stroke. So to reduce the class imbalance we use over smapling techniques to replicate some data with affecting the probabilty distribution of predictors in the data set. 

But, before that we need to remove the outliers from the dataset.



```{r}
data_balanced <- rbind(train, data_balanced_over)
data_balanced
table(data_balanced$stroke)
```

```{r}
# distribution of balanced data

# distribution for BMI
d <- density(na.omit(data_balanced$bmi))
plot(d, main="Distribution for BMI ")
polygon(d, col="green", border="blue")

# distribution for age
d <- density(na.omit(data_balanced$age))
plot(d, main="Distribution for Age ")
polygon(d, col="red", border="blue")

# distribution for avg_glucose_level
d <- density(na.omit(data_balanced$avg_glucose_level))
plot(d, main="Distribution for Avg_glucose_level")
polygon(d, col="yellow", border="blue")
```

```{r}

wn = sum(data_balanced$stroke =="0")/length(data_balanced$stroke)
wy = 1

rf <- randomForest(stroke ~., data = data_balanced, mtry =sqrt(ncol(data_balanced) - 1), classwt = c("0"=wn, "1"=wy), ntree = 500)


# predicting the income value
yhat_rf <- predict(rf, test[,-7])

# accuracy
acc_rf = mean(yhat_rf == test$stroke)

# classification metrics
cm <- confusionMatrix(yhat_rf, test$stroke, mode = "everything", positive="1")
cm
```


Applying random forest to the data
```{r}
table(test$stroke)
```
